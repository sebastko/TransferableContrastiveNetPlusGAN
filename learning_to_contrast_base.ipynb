{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(class_embedding='att', dataroot='../datasets/data_resnet', dataset='APY', disp_interval=500, evl_interval=1000, exp_idx='', gpu='1', image_embedding='res101', manualSeed=6278, matdataset=True, preprocessing=False, resume=None, save_interval=10000, standardization=False, validation=False, z_dim=100)\n",
      "('Random Seed: ', 6278)\n",
      "64 2048\n",
      "_AttributeNet(\n",
      "  (attribute): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "_RelationNet(\n",
      "  (relation): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "\u001b[31m The output dictionary is Result_baseline/GBU_APY/Rls0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianghuajie/.local/lib/python2.7/site-packages/ipykernel_launcher.py:381: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "/home/jianghuajie/.local/lib/python2.7/site-packages/ipykernel_launcher.py:382: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/jianghuajie/.local/lib/python2.7/site-packages/ipykernel_launcher.py:194: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-500; Loss: 0.192; ZSL: 0.000; H: 0.000; S: 0.000; U: 0.000;  \n",
      "Accuracy is 24.81%\n",
      "H 0.34%  S->T 26.59%  U->T 0.17%  \n",
      "Iter-1000; Loss: 0.148; ZSL: 24.806; H: 0.342; S: 26.593; U: 0.172;  \n",
      "Iter-1500; Loss: 0.118; ZSL: 24.806; H: 0.342; S: 26.593; U: 0.172;  \n",
      "Accuracy is 35.37%\n",
      "H 0.08%  S->T 55.78%  U->T 0.04%  \n",
      "Iter-2000; Loss: 0.102; ZSL: 35.375; H: 0.083; S: 55.780; U: 0.042;  \n",
      "Iter-2500; Loss: 0.085; ZSL: 35.375; H: 0.083; S: 55.780; U: 0.042;  \n",
      "Accuracy is 37.52%\n",
      "H 1.88%  S->T 62.82%  U->T 0.95%  \n",
      "Iter-3000; Loss: 0.067; ZSL: 37.518; H: 1.880; S: 62.822; U: 0.954;  \n",
      "Iter-3500; Loss: 0.044; ZSL: 37.518; H: 1.880; S: 62.822; U: 0.954;  \n",
      "Accuracy is 36.43%\n",
      "H 1.64%  S->T 67.08%  U->T 0.83%  \n",
      "Iter-4000; Loss: 0.064; ZSL: 36.430; H: 1.642; S: 67.076; U: 0.831;  \n",
      "Iter-4500; Loss: 0.066; ZSL: 36.430; H: 1.642; S: 67.076; U: 0.831;  \n",
      "Accuracy is 34.02%\n",
      "H 2.45%  S->T 70.82%  U->T 1.25%  \n",
      "Iter-5000; Loss: 0.039; ZSL: 34.015; H: 2.448; S: 70.825; U: 1.245;  \n",
      "Iter-5500; Loss: 0.048; ZSL: 34.015; H: 2.448; S: 70.825; U: 1.245;  \n",
      "Accuracy is 32.74%\n",
      "H 3.50%  S->T 72.00%  U->T 1.79%  \n",
      "Iter-6000; Loss: 0.032; ZSL: 32.739; H: 3.497; S: 72.002; U: 1.792;  \n",
      "Iter-6500; Loss: 0.052; ZSL: 32.739; H: 3.497; S: 72.002; U: 1.792;  \n",
      "Accuracy is 31.64%\n",
      "H 4.56%  S->T 73.82%  U->T 2.35%  \n",
      "Iter-7000; Loss: 0.036; ZSL: 31.642; H: 4.563; S: 73.819; U: 2.354;  \n",
      "Iter-7500; Loss: 0.025; ZSL: 31.642; H: 4.563; S: 73.819; U: 2.354;  \n",
      "Accuracy is 31.14%\n",
      "H 5.80%  S->T 75.54%  U->T 3.01%  \n",
      "Iter-8000; Loss: 0.033; ZSL: 31.137; H: 5.798; S: 75.542; U: 3.015;  \n",
      "Iter-8500; Loss: 0.033; ZSL: 31.137; H: 5.798; S: 75.542; U: 3.015;  \n",
      "Accuracy is 30.99%\n",
      "H 6.45%  S->T 78.59%  U->T 3.36%  \n",
      "Iter-9000; Loss: 0.036; ZSL: 30.990; H: 6.448; S: 78.590; U: 3.362;  \n",
      "Iter-9500; Loss: 0.029; ZSL: 30.990; H: 6.448; S: 78.590; U: 3.362;  \n",
      "Accuracy is 30.57%\n",
      "H 7.03%  S->T 80.23%  U->T 3.68%  \n",
      "\u001b[31mSave model to Result_baseline/GBU_APY/Rls0/Iter_10000.tar\u001b[0m\n",
      "Iter-10000; Loss: 0.031; ZSL: 30.568; H: 7.029; S: 80.229; U: 3.675;  \n",
      "Iter-10500; Loss: 0.042; ZSL: 30.568; H: 7.029; S: 80.229; U: 3.675;  \n",
      "Accuracy is 29.67%\n",
      "H 7.59%  S->T 81.47%  U->T 3.98%  \n",
      "Iter-11000; Loss: 0.020; ZSL: 29.668; H: 7.591; S: 81.469; U: 3.981;  \n",
      "Iter-11500; Loss: 0.018; ZSL: 29.668; H: 7.591; S: 81.469; U: 3.981;  \n",
      "Accuracy is 29.84%\n",
      "H 7.50%  S->T 81.76%  U->T 3.93%  \n",
      "Iter-12000; Loss: 0.025; ZSL: 29.838; H: 7.495; S: 81.760; U: 3.928;  \n",
      "Iter-12500; Loss: 0.035; ZSL: 29.838; H: 7.495; S: 81.760; U: 3.928;  \n",
      "Accuracy is 28.22%\n",
      "H 7.83%  S->T 82.14%  U->T 4.11%  \n",
      "Iter-13000; Loss: 0.035; ZSL: 28.217; H: 7.832; S: 82.144; U: 4.112;  \n",
      "Iter-13500; Loss: 0.033; ZSL: 28.217; H: 7.832; S: 82.144; U: 4.112;  \n",
      "Accuracy is 27.36%\n",
      "H 7.68%  S->T 82.13%  U->T 4.03%  \n",
      "Iter-14000; Loss: 0.025; ZSL: 27.355; H: 7.681; S: 82.135; U: 4.029;  \n",
      "Iter-14500; Loss: 0.023; ZSL: 27.355; H: 7.681; S: 82.135; U: 4.029;  \n",
      "Accuracy is 27.04%\n",
      "H 8.23%  S->T 81.80%  U->T 4.33%  \n",
      "Iter-15000; Loss: 0.018; ZSL: 27.041; H: 8.232; S: 81.797; U: 4.334;  \n",
      "Iter-15500; Loss: 0.021; ZSL: 27.041; H: 8.232; S: 81.797; U: 4.334;  \n",
      "Accuracy is 26.15%\n",
      "H 8.30%  S->T 81.36%  U->T 4.37%  \n",
      "Iter-16000; Loss: 0.039; ZSL: 26.149; H: 8.301; S: 81.358; U: 4.374;  \n",
      "Iter-16500; Loss: 0.016; ZSL: 26.149; H: 8.301; S: 81.358; U: 4.374;  \n",
      "Accuracy is 24.67%\n",
      "H 9.12%  S->T 81.04%  U->T 4.83%  \n",
      "Iter-17000; Loss: 0.019; ZSL: 24.667; H: 9.120; S: 81.038; U: 4.832;  \n",
      "Iter-17500; Loss: 0.026; ZSL: 24.667; H: 9.120; S: 81.038; U: 4.832;  \n",
      "Accuracy is 23.99%\n",
      "H 9.38%  S->T 80.78%  U->T 4.98%  \n",
      "Iter-18000; Loss: 0.017; ZSL: 23.986; H: 9.376; S: 80.785; U: 4.977;  \n",
      "Iter-18500; Loss: 0.013; ZSL: 23.986; H: 9.376; S: 80.785; U: 4.977;  \n",
      "Accuracy is 23.44%\n",
      "H 9.39%  S->T 80.86%  U->T 4.98%  \n",
      "Iter-19000; Loss: 0.021; ZSL: 23.444; H: 9.388; S: 80.861; U: 4.983;  \n",
      "Iter-19500; Loss: 0.016; ZSL: 23.444; H: 9.388; S: 80.861; U: 4.983;  \n",
      "Accuracy is 21.33%\n",
      "H 9.54%  S->T 80.38%  U->T 5.07%  \n",
      "\u001b[31mSave model to Result_baseline/GBU_APY/Rls0/Iter_20000.tar\u001b[0m\n",
      "Iter-20000; Loss: 0.012; ZSL: 21.327; H: 9.539; S: 80.383; U: 5.070;  \n",
      "Iter-20500; Loss: 0.013; ZSL: 21.327; H: 9.539; S: 80.383; U: 5.070;  \n",
      "Accuracy is 22.32%\n",
      "H 9.98%  S->T 79.83%  U->T 5.32%  \n",
      "Iter-21000; Loss: 0.012; ZSL: 22.318; H: 9.979; S: 79.835; U: 5.322;  \n",
      "Iter-21500; Loss: 0.015; ZSL: 22.318; H: 9.979; S: 79.835; U: 5.322;  \n",
      "Accuracy is 21.66%\n",
      "H 10.11%  S->T 79.56%  U->T 5.40%  \n",
      "Iter-22000; Loss: 0.016; ZSL: 21.662; H: 10.106; S: 79.557; U: 5.396;  \n",
      "Iter-22500; Loss: 0.007; ZSL: 21.662; H: 10.106; S: 79.557; U: 5.396;  \n",
      "Accuracy is 21.20%\n",
      "H 10.04%  S->T 79.32%  U->T 5.36%  \n",
      "Iter-23000; Loss: 0.013; ZSL: 21.198; H: 10.037; S: 79.320; U: 5.357;  \n",
      "Iter-23500; Loss: 0.009; ZSL: 21.198; H: 10.037; S: 79.320; U: 5.357;  \n",
      "Accuracy is 19.84%\n",
      "H 10.10%  S->T 79.08%  U->T 5.40%  \n",
      "Iter-24000; Loss: 0.020; ZSL: 19.843; H: 10.104; S: 79.081; U: 5.397;  \n",
      "Iter-24500; Loss: 0.012; ZSL: 19.843; H: 10.104; S: 79.081; U: 5.397;  \n",
      "Accuracy is 19.44%\n",
      "H 9.92%  S->T 78.65%  U->T 5.30%  \n",
      "Iter-25000; Loss: 0.026; ZSL: 19.435; H: 9.923; S: 78.651; U: 5.296;  \n",
      "Iter-25500; Loss: 0.004; ZSL: 19.435; H: 9.923; S: 78.651; U: 5.296;  \n",
      "Accuracy is 19.03%\n",
      "H 10.19%  S->T 78.43%  U->T 5.45%  \n",
      "Iter-26000; Loss: 0.007; ZSL: 19.025; H: 10.190; S: 78.426; U: 5.449;  \n",
      "Iter-26500; Loss: 0.014; ZSL: 19.025; H: 10.190; S: 78.426; U: 5.449;  \n",
      "Accuracy is 19.44%\n",
      "H 9.98%  S->T 78.54%  U->T 5.33%  \n",
      "Iter-27000; Loss: 0.010; ZSL: 19.442; H: 9.977; S: 78.541; U: 5.327;  \n",
      "Iter-27500; Loss: 0.008; ZSL: 19.442; H: 9.977; S: 78.541; U: 5.327;  \n",
      "Accuracy is 18.42%\n",
      "H 10.28%  S->T 77.78%  U->T 5.50%  \n",
      "Iter-28000; Loss: 0.005; ZSL: 18.420; H: 10.278; S: 77.776; U: 5.503;  \n",
      "Iter-28500; Loss: 0.007; ZSL: 18.420; H: 10.278; S: 77.776; U: 5.503;  \n",
      "Accuracy is 17.74%\n",
      "H 10.25%  S->T 78.04%  U->T 5.49%  \n",
      "Iter-29000; Loss: 0.008; ZSL: 17.741; H: 10.250; S: 78.042; U: 5.485;  \n",
      "Iter-29500; Loss: 0.007; ZSL: 17.741; H: 10.250; S: 78.042; U: 5.485;  \n",
      "Accuracy is 19.19%\n",
      "H 10.03%  S->T 77.97%  U->T 5.36%  \n",
      "\u001b[31mSave model to Result_baseline/GBU_APY/Rls0/Iter_30000.tar\u001b[0m\n",
      "Iter-30000; Loss: 0.014; ZSL: 19.186; H: 10.030; S: 77.967; U: 5.360;  \n",
      "Iter-30500; Loss: 0.007; ZSL: 19.186; H: 10.030; S: 77.967; U: 5.360;  \n",
      "Accuracy is 18.16%\n",
      "H 10.13%  S->T 77.44%  U->T 5.42%  \n",
      "Iter-31000; Loss: 0.007; ZSL: 18.162; H: 10.129; S: 77.445; U: 5.419;  \n",
      "Iter-31500; Loss: 0.015; ZSL: 18.162; H: 10.129; S: 77.445; U: 5.419;  \n",
      "Accuracy is 18.34%\n",
      "H 10.15%  S->T 77.62%  U->T 5.43%  \n",
      "Iter-32000; Loss: 0.015; ZSL: 18.336; H: 10.150; S: 77.624; U: 5.430;  \n",
      "Iter-32500; Loss: 0.009; ZSL: 18.336; H: 10.150; S: 77.624; U: 5.430;  \n",
      "Accuracy is 18.10%\n",
      "H 10.03%  S->T 77.02%  U->T 5.37%  \n",
      "Iter-33000; Loss: 0.005; ZSL: 18.102; H: 10.032; S: 77.022; U: 5.365;  \n",
      "Iter-33500; Loss: 0.003; ZSL: 18.102; H: 10.032; S: 77.022; U: 5.365;  \n",
      "Accuracy is 18.73%\n",
      "H 9.96%  S->T 77.38%  U->T 5.32%  \n",
      "Iter-34000; Loss: 0.003; ZSL: 18.726; H: 9.956; S: 77.380; U: 5.320;  \n",
      "Iter-34500; Loss: 0.010; ZSL: 18.726; H: 9.956; S: 77.380; U: 5.320;  \n",
      "Accuracy is 17.75%\n",
      "H 10.00%  S->T 76.81%  U->T 5.35%  \n",
      "Iter-35000; Loss: 0.010; ZSL: 17.745; H: 9.999; S: 76.807; U: 5.347;  \n",
      "Iter-35500; Loss: 0.017; ZSL: 17.745; H: 9.999; S: 76.807; U: 5.347;  \n",
      "Accuracy is 19.12%\n",
      "H 9.99%  S->T 76.87%  U->T 5.34%  \n",
      "Iter-36000; Loss: 0.016; ZSL: 19.120; H: 9.986; S: 76.874; U: 5.340;  \n",
      "Iter-36500; Loss: 0.006; ZSL: 19.120; H: 9.986; S: 76.874; U: 5.340;  \n",
      "Accuracy is 19.06%\n",
      "H 10.12%  S->T 76.37%  U->T 5.42%  \n",
      "Iter-37000; Loss: 0.004; ZSL: 19.061; H: 10.125; S: 76.374; U: 5.422;  \n",
      "Iter-37500; Loss: 0.003; ZSL: 19.061; H: 10.125; S: 76.374; U: 5.422;  \n",
      "Accuracy is 19.21%\n",
      "H 10.07%  S->T 76.90%  U->T 5.39%  \n",
      "Iter-38000; Loss: 0.002; ZSL: 19.212; H: 10.071; S: 76.896; U: 5.388;  \n",
      "Iter-38500; Loss: 0.006; ZSL: 19.212; H: 10.071; S: 76.896; U: 5.388;  \n",
      "Accuracy is 19.17%\n",
      "H 9.82%  S->T 76.27%  U->T 5.25%  \n",
      "Iter-39000; Loss: 0.003; ZSL: 19.169; H: 9.824; S: 76.271; U: 5.250;  \n",
      "Iter-39500; Loss: 0.006; ZSL: 19.169; H: 9.824; S: 76.271; U: 5.250;  \n",
      "Accuracy is 18.75%\n",
      "H 9.77%  S->T 75.93%  U->T 5.22%  \n",
      "\u001b[31mSave model to Result_baseline/GBU_APY/Rls0/Iter_40000.tar\u001b[0m\n",
      "Iter-40000; Loss: 0.002; ZSL: 18.748; H: 9.765; S: 75.926; U: 5.218;  \n",
      "Iter-40500; Loss: 0.002; ZSL: 18.748; H: 9.765; S: 75.926; U: 5.218;  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 19.15%\n",
      "H 9.50%  S->T 76.14%  U->T 5.07%  \n",
      "Iter-41000; Loss: 0.001; ZSL: 19.149; H: 9.504; S: 76.142; U: 5.068;  \n",
      "Iter-41500; Loss: 0.002; ZSL: 19.149; H: 9.504; S: 76.142; U: 5.068;  \n",
      "Accuracy is 18.54%\n",
      "H 9.61%  S->T 75.91%  U->T 5.13%  \n",
      "Iter-42000; Loss: 0.020; ZSL: 18.542; H: 9.614; S: 75.906; U: 5.132;  \n",
      "Iter-42500; Loss: 0.006; ZSL: 18.542; H: 9.614; S: 75.906; U: 5.132;  \n",
      "Accuracy is 19.51%\n",
      "H 9.77%  S->T 75.97%  U->T 5.22%  \n",
      "Iter-43000; Loss: 0.003; ZSL: 19.513; H: 9.767; S: 75.966; U: 5.219;  \n",
      "Iter-43500; Loss: 0.001; ZSL: 19.513; H: 9.767; S: 75.966; U: 5.219;  \n",
      "Accuracy is 19.22%\n",
      "H 9.74%  S->T 75.85%  U->T 5.20%  \n",
      "Iter-44000; Loss: 0.008; ZSL: 19.221; H: 9.739; S: 75.852; U: 5.204;  \n",
      "Iter-44500; Loss: 0.001; ZSL: 19.221; H: 9.739; S: 75.852; U: 5.204;  \n",
      "Accuracy is 19.60%\n",
      "H 9.74%  S->T 75.69%  U->T 5.21%  \n",
      "Iter-45000; Loss: 0.001; ZSL: 19.595; H: 9.743; S: 75.694; U: 5.207;  \n",
      "Iter-45500; Loss: 0.001; ZSL: 19.595; H: 9.743; S: 75.694; U: 5.207;  \n",
      "Accuracy is 18.50%\n",
      "H 9.54%  S->T 75.25%  U->T 5.09%  \n",
      "Iter-46000; Loss: 0.001; ZSL: 18.499; H: 9.537; S: 75.246; U: 5.091;  \n",
      "Iter-46500; Loss: 0.002; ZSL: 18.499; H: 9.537; S: 75.246; U: 5.091;  \n",
      "Accuracy is 19.37%\n",
      "H 9.59%  S->T 75.72%  U->T 5.12%  \n",
      "Iter-47000; Loss: 0.001; ZSL: 19.373; H: 9.590; S: 75.718; U: 5.119;  \n",
      "Iter-47500; Loss: 0.003; ZSL: 19.373; H: 9.590; S: 75.718; U: 5.119;  \n",
      "Accuracy is 19.66%\n",
      "H 9.73%  S->T 75.41%  U->T 5.20%  \n",
      "Iter-48000; Loss: 0.003; ZSL: 19.664; H: 9.730; S: 75.405; U: 5.201;  \n",
      "Iter-48500; Loss: 0.001; ZSL: 19.664; H: 9.730; S: 75.405; U: 5.201;  \n",
      "Accuracy is 19.44%\n",
      "H 9.76%  S->T 75.44%  U->T 5.22%  \n",
      "Iter-49000; Loss: 0.001; ZSL: 19.436; H: 9.762; S: 75.439; U: 5.219;  \n",
      "Iter-49500; Loss: 0.001; ZSL: 19.436; H: 9.762; S: 75.439; U: 5.219;  \n",
      "Accuracy is 19.07%\n",
      "H 9.67%  S->T 75.51%  U->T 5.16%  \n",
      "\u001b[31mSave model to Result_baseline/GBU_APY/Rls0/Iter_50000.tar\u001b[0m\n",
      "Iter-50000; Loss: 0.000; ZSL: 19.074; H: 9.667; S: 75.507; U: 5.164;  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn as nn\n",
    "\n",
    "from termcolor import cprint\n",
    "from time import gmtime, strftime\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from dataset_loader import FeatDataLayer, DATA_LOADER\n",
    "from models import _AttributeNet, _RelationNet, _param\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default='APY', help='FLO')\n",
    "parser.add_argument('--dataroot', default='../datasets/data_resnet',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--matdataset', default=True, help='Data in matlab format')\n",
    "parser.add_argument('--image_embedding', default='res101')\n",
    "parser.add_argument('--class_embedding', default='att')\n",
    "parser.add_argument('--preprocessing', action='store_true', default=False,\n",
    "                    help='enbale MinMaxScaler on visual features')\n",
    "parser.add_argument('--standardization', action='store_true', default=False)\n",
    "parser.add_argument('--validation', action='store_true', default=False, help='enable cross validation mode')\n",
    "\n",
    "parser.add_argument('--gpu', default='1', type=str, help='index of GPU to use')\n",
    "parser.add_argument('--exp_idx', default='', type=str, help='exp idx')\n",
    "parser.add_argument('--manualSeed', type=int, default=6278, help='manual seed')\n",
    "parser.add_argument('--resume',  type=str, help='the model to resume')\n",
    "\n",
    "parser.add_argument('--z_dim',  type=int, default=100, help='dimension of the random vector z')\n",
    "parser.add_argument('--disp_interval', type=int, default=500)\n",
    "parser.add_argument('--save_interval', type=int, default=10000)\n",
    "parser.add_argument('--evl_interval',  type=int, default=1000)\n",
    "\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "print(opt)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu\n",
    "\n",
    "\"\"\" hyper-parameter  \"\"\"\n",
    "opt.REG_W_LAMBDA = 0\n",
    "\n",
    "\n",
    "opt.lr = 0.00001\n",
    "opt.batch_size = 32  # 512\n",
    "\n",
    "\"\"\" hyper-parameter for testing\"\"\"\n",
    "\n",
    "\n",
    "if opt.manualSeed is None:\n",
    "    opt.manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "torch.cuda.manual_seed_all(opt.manualSeed)\n",
    "\n",
    "\n",
    "def train():\n",
    "    param = _param()\n",
    "    dataset = DATA_LOADER(opt)\n",
    "    param.X_dim = dataset.feature_dim\n",
    "\n",
    "    data_layer = FeatDataLayer(dataset.train_label.numpy(), dataset.train_feature.numpy(), opt)\n",
    "    result = Result()\n",
    "    result_gzsl = Result()\n",
    "    \n",
    "    print dataset.att_dim, dataset.feature_dim\n",
    "    APnet = _AttributeNet(dataset.att_dim, dataset.feature_dim).cuda()\n",
    "    APnet.apply(weights_init)\n",
    "    print(APnet)\n",
    "    \n",
    "    Rnet = _RelationNet(dataset.feature_dim).cuda()\n",
    "    Rnet.apply(weights_init)\n",
    "    print(Rnet)\n",
    "    \n",
    "    exp_info = 'GBU_{}'.format(opt.dataset)\n",
    "    exp_params = 'Rls{}'.format(opt.REG_W_LAMBDA)\n",
    "\n",
    "    out_dir  = 'Result_baseline/{:s}'.format(exp_info)\n",
    "    out_subdir = 'Result_baseline/{:s}/{:s}'.format(exp_info, exp_params)\n",
    "    if not os.path.exists('Result_baseline'):\n",
    "        os.mkdir('Result_baseline')\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    if not os.path.exists(out_subdir):\n",
    "        os.mkdir(out_subdir)\n",
    "\n",
    "    cprint(\" The output dictionary is {}\".format(out_subdir), 'red')\n",
    "    log_dir = out_subdir + '/log_{:s}_{}.txt'.format(exp_info, opt.exp_idx)\n",
    "    with open(log_dir, 'w') as f:\n",
    "        f.write('Training Start:')\n",
    "        f.write(strftime(\"%a, %d %b %Y %H:%M:%S +0000\", gmtime()) + '\\n')\n",
    "\n",
    "    start_step = 0\n",
    "\n",
    "    if opt.resume:\n",
    "        if os.path.isfile(opt.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(opt.resume))\n",
    "            checkpoint = torch.load(opt.resume)\n",
    "            APnet.load_state_dict(checkpoint['state_dict_AP'])\n",
    "            start_step = checkpoint['it']\n",
    "            print(checkpoint['log'])\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(opt.resume))\n",
    "\n",
    "    optimizerAP = optim.Adam(APnet.parameters(), lr=opt.lr, betas=(0.5, 0.9))\n",
    "    optimizerR = optim.Adam(Rnet.parameters(), lr=opt.lr, betas=(0.5, 0.9))\n",
    "    nets = [APnet, Rnet]\n",
    "    \n",
    "    acc = 0\n",
    "    H = 0\n",
    "    S = 0\n",
    "    U = 0\n",
    "    \n",
    "    for it in range(start_step, 50000+1):      \n",
    "        blobs = data_layer.forward()\n",
    "        batch_feats = blobs['data']             # image data\n",
    "        batch_labels = blobs['labels'].astype(int)  # class labels\n",
    "        \n",
    "        support_attr = dataset.attribute[dataset.train_class].cuda()\n",
    "        class_num = dataset.train_class.shape[0]\n",
    "        \n",
    "        batch_images = torch.from_numpy(batch_feats).cuda()\n",
    "\n",
    "        batch_ext = batch_images.unsqueeze(0).repeat(class_num,1,1)\n",
    "        batch_ext = torch.transpose(batch_ext,0,1)\n",
    "                        \n",
    "        # forward\n",
    "        semantic_proto = APnet(support_attr)\n",
    "        semantic_proto_ext = semantic_proto.unsqueeze(0).repeat(opt.batch_size,1,1)\n",
    "        # relation_pairs = torch.cat([semantic_proto_ext, batch_ext],2).view(-1,dataset.feature_dim + dataset.feature_dim)\n",
    "        relation_pairs = semantic_proto_ext * batch_ext\n",
    "        relations = Rnet(relation_pairs).view(-1,class_num)\n",
    "        \n",
    "        # label transform\n",
    "        support_labels = dataset.train_class.numpy()\n",
    "        re_batch_labels = np.zeros_like(batch_labels)\n",
    "        for i in range(class_num):\n",
    "            re_batch_labels[batch_labels==support_labels[i]] = i\n",
    "        re_batch_labels = torch.LongTensor(re_batch_labels)\n",
    "        \n",
    "        bce = nn.BCELoss().cuda()\n",
    "        one_hot_labels = torch.zeros(opt.batch_size, class_num).scatter_(1, re_batch_labels.view(-1,1), 1).cuda()\n",
    "        loss = bce(relations,one_hot_labels)\n",
    "        \n",
    "        reset_grad(nets)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizerAP.step()\n",
    "        optimizerR.step()\n",
    "\n",
    "\n",
    "        if it % opt.evl_interval == 0 and it >= 100:\n",
    "            APnet.eval()\n",
    "            Rnet.eval()\n",
    "            acc = eval_test(it, APnet, Rnet, dataset, param, result)\n",
    "            if result.save_model:\n",
    "                files2remove = glob.glob(out_subdir + '/Best_model_ZSL_*')\n",
    "                for _i in files2remove:\n",
    "                    os.remove(_i)\n",
    "                # best_acc = result.acc_list[-1]\n",
    "                save_model(it, APnet, Rnet, opt.manualSeed, log_text,\n",
    "                           out_subdir + '/Best_model_ZSL_Acc_{:.2f}.tar'.format(result.acc_list[-1]))\n",
    "\n",
    "            H, S, U = eval_test_gzsl(it, APnet, Rnet, dataset, param, result_gzsl)\n",
    "            if result_gzsl.save_model:\n",
    "                files2remove = glob.glob(out_subdir + '/Best_model_GZSL_*')\n",
    "                for _i in files2remove:\n",
    "                    os.remove(_i)\n",
    "                # best_acc_gzsl = result.acc_list[-1]\n",
    "                save_model(it, APnet, Rnet, opt.manualSeed, log_text,\n",
    "                           out_subdir + '/Best_model_GZSL_H_{:.2f}_S_{:.2f}_U_{:.2f}.tar'.format(result_gzsl.best_acc,\n",
    "                                                                                                 result_gzsl.best_acc_S_T,\n",
    "                                                                                                 result_gzsl.best_acc_U_T))\n",
    "\n",
    "            APnet.train()\n",
    "            Rnet.train()\n",
    "\n",
    "        if it % opt.save_interval == 0 and it:\n",
    "            save_model(it, APnet, Rnet, opt.manualSeed, log_text,\n",
    "                       out_subdir + '/Iter_{:d}.tar'.format(it))\n",
    "            cprint('Save model to ' + out_subdir + '/Iter_{:d}.tar'.format(it), 'red')\n",
    "        \n",
    "        if it % opt.disp_interval == 0 and it:\n",
    "\n",
    "            log_text = 'Iter-{}; Loss: {:.3f}; ZSL: {:.3f}; H: {:.3f}; S: {:.3f}; U: {:.3f};  '\\\n",
    "                        .format(it, loss.data[0], acc, H, S, U)\n",
    "            print(log_text)\n",
    "            with open(log_dir, 'a') as f:\n",
    "                f.write(log_text+'\\n')\n",
    "\n",
    "def save_model(it, APnet, Rnet, random_seed, log, fout):\n",
    "    torch.save({\n",
    "        'it': it + 1,\n",
    "        'state_dict_AP': APnet.state_dict(),\n",
    "        'state_dict_R': Rnet.state_dict(),\n",
    "        'random_seed': random_seed,\n",
    "        'log': log,\n",
    "    }, fout)\n",
    "\n",
    "\n",
    "def eval_test(it, APnet, Rnet, dataset, param, result):\n",
    "    support_attr = torch.from_numpy(dataset.test_att).cuda()\n",
    "    class_num = support_attr.shape[0]\n",
    "    \n",
    "    # label transform\n",
    "    support_labels = np.array(dataset.unseenclasses)\n",
    "    test_labels = np.array(dataset.test_unseen_label)\n",
    "    \n",
    "    test_images = dataset.test_unseen_feature.cuda()\n",
    "    preds = np.zeros_like(test_labels)\n",
    "    \n",
    "    start = 0 \n",
    "    while start < test_labels.shape[0]:\n",
    "        if start + opt.batch_size > test_labels.shape[0]:\n",
    "            end = test_labels.shape[0]\n",
    "        else:\n",
    "            end = start + opt.batch_size\n",
    "        \n",
    "        batch_images = test_images[start:end]\n",
    "        \n",
    "        batch_ext = batch_images.unsqueeze(0).repeat(class_num,1,1)\n",
    "        batch_ext = torch.transpose(batch_ext,0,1)\n",
    "\n",
    "        # forward\n",
    "        semantic_proto = APnet(support_attr)\n",
    "        semantic_proto_ext = semantic_proto.unsqueeze(0).repeat(end-start,1,1)\n",
    "        # relation_pairs = torch.cat([semantic_proto_ext, batch_ext],2).view(-1,dataset.feature_dim + dataset.feature_dim)\n",
    "        relation_pairs = semantic_proto_ext * batch_ext\n",
    "        relations = Rnet(relation_pairs).view(-1,class_num)\n",
    "        prob = relations.data.cpu().numpy()\n",
    "        pred = np.argmax(prob,1)\n",
    "        preds[start:end]=pred\n",
    "        \n",
    "        start = end\n",
    "\n",
    "    # produce MCA\n",
    "    grounds = test_labels\n",
    "    predicts = support_labels[preds]\n",
    "\n",
    "    acc = np.zeros(class_num)\n",
    "    for i in range(class_num):\n",
    "        index = grounds == support_labels[i]\n",
    "        acc[i] = (predicts[index] == support_labels[i]).mean()\n",
    "    acc = acc.mean() * 100\n",
    "\n",
    "    result.acc_list += [acc]\n",
    "    result.iter_list += [it]\n",
    "    result.save_model = False\n",
    "    if acc > result.best_acc:\n",
    "        result.best_acc = acc\n",
    "        result.best_iter = it\n",
    "        result.save_model = True\n",
    "    print(\"Accuracy is {:.2f}%\".format(acc))\n",
    "    return acc\n",
    "\n",
    "\n",
    "def eval_test_gzsl(it, APnet, Rnet, dataset, param, result):\n",
    "    support_attr = dataset.attribute.cuda()\n",
    "    class_num = support_attr.shape[0]\n",
    "    \n",
    "    # label transform\n",
    "    support_labels = np.array(dataset.allclasses)\n",
    "    \n",
    "    \"\"\"  S -> T\n",
    "    \"\"\"\n",
    "    test_labels = np.array(dataset.test_seen_label)\n",
    "    test_images = dataset.test_seen_feature.cuda()\n",
    "    preds = np.zeros_like(test_labels)\n",
    "    \n",
    "    start = 0 \n",
    "    while start < test_labels.shape[0]:\n",
    "        if start + opt.batch_size > test_labels.shape[0]:\n",
    "            end = test_labels.shape[0]\n",
    "        else:\n",
    "            end = start + opt.batch_size\n",
    "        \n",
    "        batch_images = test_images[start:end]\n",
    "        \n",
    "        batch_ext = batch_images.unsqueeze(0).repeat(class_num,1,1)\n",
    "        batch_ext = torch.transpose(batch_ext,0,1)\n",
    "\n",
    "        # forward\n",
    "        semantic_proto = APnet(support_attr)\n",
    "        semantic_proto_ext = semantic_proto.unsqueeze(0).repeat(end-start,1,1)\n",
    "        # relation_pairs = torch.cat([semantic_proto_ext, batch_ext],2).view(-1,dataset.feature_dim + dataset.feature_dim)\n",
    "        relation_pairs = semantic_proto_ext * batch_ext\n",
    "        relations = Rnet(relation_pairs).view(-1,class_num)\n",
    "        prob = relations.data.cpu().numpy()\n",
    "        pred = np.argmax(prob,1)\n",
    "        preds[start:end]=pred\n",
    "        \n",
    "        start = end\n",
    "\n",
    "    # produce MCA\n",
    "    label_T = test_labels\n",
    "    num_seen_classes = dataset.ntrain_class\n",
    "    seen_classes = np.array(dataset.seenclasses)\n",
    "    \n",
    "    acc = np.zeros(num_seen_classes)\n",
    "    for i in range(num_seen_classes):\n",
    "        acc[i] = (preds[label_T == seen_classes[i]] == seen_classes[i]).mean()\n",
    "    acc_S_T = acc.mean() * 100\n",
    "\n",
    "    \"\"\"  U -> T\n",
    "    \"\"\"\n",
    "    test_labels = np.array(dataset.test_unseen_label)\n",
    "    test_images = dataset.test_unseen_feature.cuda()\n",
    "    preds = np.zeros_like(test_labels)\n",
    "    \n",
    "    start = 0 \n",
    "    while start < test_labels.shape[0]:\n",
    "        if start + opt.batch_size > test_labels.shape[0]:\n",
    "            end = test_labels.shape[0]\n",
    "        else:\n",
    "            end = start + opt.batch_size\n",
    "        \n",
    "        batch_images = test_images[start:end]\n",
    "        \n",
    "        batch_ext = batch_images.unsqueeze(0).repeat(class_num,1,1)\n",
    "        batch_ext = torch.transpose(batch_ext,0,1)\n",
    "\n",
    "        # forward\n",
    "        semantic_proto = APnet(support_attr)\n",
    "        semantic_proto_ext = semantic_proto.unsqueeze(0).repeat(end-start,1,1)\n",
    "        # relation_pairs = torch.cat([semantic_proto_ext, batch_ext],2).view(-1,dataset.feature_dim + dataset.feature_dim)\n",
    "        relation_pairs = semantic_proto_ext * batch_ext\n",
    "        relations = Rnet(relation_pairs).view(-1,class_num)\n",
    "        prob = relations.data.cpu().numpy()\n",
    "        pred = np.argmax(prob,1)\n",
    "        preds[start:end]=pred\n",
    "        \n",
    "        start = end\n",
    "\n",
    "    # produce MCA\n",
    "    label_T = test_labels\n",
    "    num_unseen_classes = dataset.ntest_class\n",
    "    unseen_classes = np.array(dataset.unseenclasses)\n",
    "    \n",
    "    acc = np.zeros(num_unseen_classes)\n",
    "    for i in range(num_unseen_classes):\n",
    "        acc[i] = (preds[label_T == unseen_classes[i]] == unseen_classes[i]).mean()\n",
    "    acc_U_T = acc.mean() * 100\n",
    "    \n",
    "    acc = (2 * acc_S_T * acc_U_T) / (acc_S_T + acc_U_T)\n",
    "\n",
    "    result.acc_list += [acc]\n",
    "    result.iter_list += [it]\n",
    "    result.save_model = False\n",
    "    if acc > result.best_acc:\n",
    "        result.best_acc = acc\n",
    "        result.best_iter = it\n",
    "        result.best_acc_S_T = acc_S_T\n",
    "        result.best_acc_U_T = acc_U_T\n",
    "        result.save_model = True\n",
    "\n",
    "    print(\"H {:.2f}%  S->T {:.2f}%  U->T {:.2f}%  \".format(acc, acc_S_T, acc_U_T))\n",
    "    return acc, acc_S_T, acc_U_T\n",
    "\n",
    "\n",
    "class Result(object):\n",
    "    def __init__(self):\n",
    "        self.best_acc = 0.0\n",
    "        self.best_iter = 0.0\n",
    "        self.best_acc_S_T = 0.0\n",
    "        self.best_acc_U_T = 0.0\n",
    "        self.acc_list = []\n",
    "        self.iter_list = []\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if 'Linear' in classname:\n",
    "        init.xavier_normal(m.weight.data)\n",
    "        init.constant(m.bias, 0.0)\n",
    "\n",
    "\n",
    "def reset_grad(nets):\n",
    "    for net in nets:\n",
    "        net.zero_grad()\n",
    "\n",
    "\n",
    "def label2mat(labels, y_dim):\n",
    "    c = np.zeros([labels.shape[0], y_dim])\n",
    "    for idx, d in enumerate(labels):\n",
    "        c[idx, d] = 1\n",
    "    return c\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
